{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering and Classifying Livestock Farming Profiles to Identify Agricultural Vulnerability in Nepal\n",
        "\n",
        "## A Machine Learning Approach\n",
        "\n",
        "**Author:** ML Assignment Project  \n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### Background\n",
        "\n",
        "Livestock farming is an essential part of Nepal's rural economy, providing income, nutrition, and a critical social safety net for millions of households. However, the agricultural landscape is not uniform; farming systems vary dramatically across the diverse ecological zones of the country (Terai, Hills, and Mountains).\n",
        "\n",
        "This study applies machine learning techniques to a nationally representative dataset to:\n",
        "1. **Identify and characterize** distinct livestock farming profiles using K-Means clustering\n",
        "2. **Develop an interpretable classification model** using Decision Trees to understand vulnerability drivers\n",
        "\n",
        "### Data Source\n",
        "National Sample Census of Agriculture 2021-22 (NSCA 2078), National Statistics Office (NSO), Government of Nepal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup and Data Loading\n",
        "\n",
        "### 1.1 Install Required Libraries (for Google Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries (uncomment if running in Google Colab)\n",
        "# !pip install geopandas folium mapclassify -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    confusion_matrix, \n",
        "    accuracy_score,\n",
        "    silhouette_score\n",
        ")\n",
        "\n",
        "# Geographic visualization (optional - will handle gracefully if not available)\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "    GEOPANDAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GEOPANDAS_AVAILABLE = False\n",
        "    print(\"Note: geopandas not available. Map visualizations will be skipped.\")\n",
        "    print(\"Install with: pip install geopandas\")\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Load Data (Google Colab Compatible)\n",
        "\n",
        "**Option A:** Upload files directly (recommended for Colab)  \n",
        "**Option B:** Mount Google Drive and load from there  \n",
        "**Option C:** Load from local path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect environment and set up data loading\n",
        "import os\n",
        "\n",
        "# Check if running in Google Colab\n",
        "IN_COLAB = 'google.colab' in str(get_ipython()) if 'get_ipython' in dir() else False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab environment\")\n",
        "    print(\"\\nPlease upload the three CSV files when prompted:\")\n",
        "    print(\"1. table-1.-number-of-holdings-and-area-by-district-.csv\")\n",
        "    print(\"2. table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv\")\n",
        "    print(\"3. table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv\")\n",
        "    \n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Get uploaded file names\n",
        "    file_names = list(uploaded.keys())\n",
        "    print(f\"\\nUploaded files: {file_names}\")\n",
        "else:\n",
        "    print(\"Running in local environment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "# Update these paths according to your setup\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Files uploaded to Colab's working directory\n",
        "    holdings_area_path = 'table-1.-number-of-holdings-and-area-by-district-.csv'\n",
        "    irrigation_path = 'table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv'\n",
        "    livestock_path = 'table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv'\n",
        "else:\n",
        "    # Local paths - update as needed\n",
        "    base_path = '/Users/eklakdangaura/College/ML/Assignment/Datasets/'\n",
        "    holdings_area_path = base_path + 'table-1.-number-of-holdings-and-area-by-district-.csv'\n",
        "    irrigation_path = base_path + 'table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv'\n",
        "    livestock_path = base_path + 'table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the three datasets\n",
        "print(\"Loading datasets...\\n\")\n",
        "\n",
        "# Dataset 1: Holdings and Area by District\n",
        "df_holdings = pd.read_csv(holdings_area_path, sep='\\t')\n",
        "print(f\"1. Holdings & Area Dataset: {df_holdings.shape[0]} rows, {df_holdings.shape[1]} columns\")\n",
        "\n",
        "# Dataset 2: Irrigation Data\n",
        "df_irrigation = pd.read_csv(irrigation_path, sep='\\t')\n",
        "print(f\"2. Irrigation Dataset: {df_irrigation.shape[0]} rows, {df_irrigation.shape[1]} columns\")\n",
        "\n",
        "# Dataset 3: Livestock Data\n",
        "df_livestock = pd.read_csv(livestock_path)\n",
        "print(f\"3. Livestock Dataset: {df_livestock.shape[0]} rows, {df_livestock.shape[1]} columns\")\n",
        "\n",
        "print(\"\\n✓ All datasets loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Explore Raw Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Holdings & Area Dataset\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET 1: Holdings and Area by District\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nColumns:\", df_holdings.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df_holdings.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Irrigation Dataset\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET 2: Irrigation Data\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nColumns:\", df_irrigation.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df_irrigation.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore Livestock Dataset\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET 3: Livestock Data\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nColumns:\", df_livestock.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df_livestock.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Data Preprocessing and Feature Engineering\n",
        "\n",
        "### 2.1 Clean and Standardize District Names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to clean district names for consistent merging\n",
        "def clean_district_name(name):\n",
        "    \"\"\"Standardize district names by removing whitespace and converting to lowercase.\"\"\"\n",
        "    if pd.isna(name):\n",
        "        return name\n",
        "    return str(name).strip().lower()\n",
        "\n",
        "# Clean district names in all datasets\n",
        "# Dataset 1: Holdings\n",
        "df_holdings['district_clean'] = df_holdings['Districts'].apply(clean_district_name)\n",
        "\n",
        "# Dataset 2: Irrigation\n",
        "df_irrigation['district_clean'] = df_irrigation['Districts'].apply(clean_district_name)\n",
        "\n",
        "# Dataset 3: Livestock\n",
        "df_livestock['district_clean'] = df_livestock['District'].apply(clean_district_name)\n",
        "\n",
        "# Display unique district counts\n",
        "print(f\"Holdings dataset: {df_holdings['district_clean'].nunique()} districts\")\n",
        "print(f\"Irrigation dataset: {df_irrigation['district_clean'].nunique()} districts\")\n",
        "print(f\"Livestock dataset: {df_livestock['district_clean'].nunique()} districts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for any district name mismatches\n",
        "holdings_districts = set(df_holdings['district_clean'].dropna())\n",
        "irrigation_districts = set(df_irrigation['district_clean'].dropna())\n",
        "livestock_districts = set(df_livestock['district_clean'].dropna())\n",
        "\n",
        "# Find common districts\n",
        "common_districts = holdings_districts & irrigation_districts & livestock_districts\n",
        "print(f\"Common districts across all datasets: {len(common_districts)}\")\n",
        "\n",
        "# Check for mismatches\n",
        "all_districts = holdings_districts | irrigation_districts | livestock_districts\n",
        "if len(all_districts) != len(common_districts):\n",
        "    print(\"\\nDistricts only in specific datasets:\")\n",
        "    print(f\"  Only in Holdings: {holdings_districts - common_districts}\")\n",
        "    print(f\"  Only in Irrigation: {irrigation_districts - common_districts}\")\n",
        "    print(f\"  Only in Livestock: {livestock_districts - common_districts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Merge Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select relevant columns from each dataset before merging\n",
        "\n",
        "# From Holdings dataset\n",
        "df_holdings_select = df_holdings[[\n",
        "    'district_clean', 'Districts', 'Number of holdings', \n",
        "    'Total wet  area (ha)', 'Total dry  area (ha)', 'Total  area (ha)'\n",
        "]].copy()\n",
        "df_holdings_select.columns = [\n",
        "    'district_clean', 'district_name', 'num_holdings',\n",
        "    'wet_area_ha', 'dry_area_ha', 'total_area_ha'\n",
        "]\n",
        "\n",
        "# From Irrigation dataset\n",
        "df_irrigation_select = df_irrigation[[\n",
        "    'district_clean', 'No. of holdings reporting irrigation', \n",
        "    'Total area (ha) of irrigation'\n",
        "]].copy()\n",
        "df_irrigation_select.columns = [\n",
        "    'district_clean', 'holdings_with_irrigation', 'irrigated_area_ha'\n",
        "]\n",
        "\n",
        "# From Livestock dataset\n",
        "df_livestock_select = df_livestock[[\n",
        "    'district_clean', 'Total number of holdings', 'Number of holdings reporting livestock',\n",
        "    'No. of  cattles', 'No. of buffalo', 'No. of goat/chyangra', \n",
        "    'No. of pigs/boar', 'No. of poultry(chicken)', 'No. of sheep'\n",
        "]].copy()\n",
        "df_livestock_select.columns = [\n",
        "    'district_clean', 'total_holdings_livestock', 'holdings_with_livestock',\n",
        "    'num_cattle', 'num_buffalo', 'num_goats', 'num_pigs', 'num_poultry', 'num_sheep'\n",
        "]\n",
        "\n",
        "print(\"Selected columns from each dataset:\")\n",
        "print(f\"  Holdings: {df_holdings_select.shape}\")\n",
        "print(f\"  Irrigation: {df_irrigation_select.shape}\")\n",
        "print(f\"  Livestock: {df_livestock_select.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all datasets on district_clean\n",
        "df_merged = df_holdings_select.merge(\n",
        "    df_irrigation_select, on='district_clean', how='inner'\n",
        ").merge(\n",
        "    df_livestock_select, on='district_clean', how='inner'\n",
        ")\n",
        "\n",
        "print(f\"Merged dataset shape: {df_merged.shape}\")\n",
        "print(f\"Number of districts: {df_merged['district_clean'].nunique()}\")\n",
        "print(\"\\nMerged dataset preview:\")\n",
        "df_merged.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in merged dataset:\")\n",
        "missing = df_merged.isnull().sum()\n",
        "print(missing[missing > 0] if missing.any() else \"No missing values!\")\n",
        "\n",
        "# Display data types\n",
        "print(\"\\nData types:\")\n",
        "print(df_merged.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Feature Engineering\n",
        "\n",
        "Create derived features that capture agricultural and livestock characteristics:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a copy for feature engineering\n",
        "df = df_merged.copy()\n",
        "\n",
        "# Handle any missing or invalid values\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert numeric columns that might be strings\n",
        "numeric_cols = ['num_holdings', 'wet_area_ha', 'dry_area_ha', 'total_area_ha',\n",
        "                'holdings_with_irrigation', 'irrigated_area_ha',\n",
        "                'num_cattle', 'num_buffalo', 'num_goats', 'num_pigs', 'num_poultry', 'num_sheep']\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop any rows with NaN after conversion\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"Dataset after cleaning: {df.shape[0]} districts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Engineering: Create derived features\n",
        "print(\"Creating engineered features...\\n\")\n",
        "\n",
        "# 1. Livestock density per holding\n",
        "df['cattle_per_holding'] = df['num_cattle'] / df['num_holdings']\n",
        "df['buffalo_per_holding'] = df['num_buffalo'] / df['num_holdings']\n",
        "df['goat_per_holding'] = df['num_goats'] / df['num_holdings']\n",
        "df['pig_per_holding'] = df['num_pigs'] / df['num_holdings']\n",
        "df['poultry_per_holding'] = df['num_poultry'] / df['num_holdings']\n",
        "df['sheep_per_holding'] = df['num_sheep'] / df['num_holdings']\n",
        "\n",
        "# 2. Total livestock per holding (excluding poultry as it has different scale)\n",
        "df['total_large_livestock'] = df['num_cattle'] + df['num_buffalo'] + df['num_goats'] + df['num_pigs'] + df['num_sheep']\n",
        "df['total_livestock_per_holding'] = df['total_large_livestock'] / df['num_holdings']\n",
        "\n",
        "# 3. Land-related features\n",
        "df['avg_land_holding'] = df['total_area_ha'] / df['num_holdings']  # Average land size per holding\n",
        "df['wet_land_ratio'] = df['wet_area_ha'] / df['total_area_ha']  # Proportion of wet (irrigated potential) land\n",
        "df['irrigated_land_pct'] = (df['irrigated_area_ha'] / df['total_area_ha']) * 100  # % of land actually irrigated\n",
        "\n",
        "# 4. Livestock composition ratios\n",
        "df['cattle_buffalo_ratio'] = df['num_cattle'] / (df['num_buffalo'] + 1)  # Cattle vs Buffalo preference\n",
        "df['small_livestock_ratio'] = (df['num_goats'] + df['num_sheep']) / (df['total_large_livestock'] + 1)  # Small vs large livestock\n",
        "\n",
        "# 5. Agricultural intensity\n",
        "df['irrigation_coverage_pct'] = (df['holdings_with_irrigation'] / df['num_holdings']) * 100\n",
        "df['livestock_density_per_ha'] = df['total_large_livestock'] / df['total_area_ha']  # Livestock per hectare\n",
        "\n",
        "print(\"✓ Engineered features created:\")\n",
        "new_features = [\n",
        "    'cattle_per_holding', 'buffalo_per_holding', 'goat_per_holding', \n",
        "    'pig_per_holding', 'poultry_per_holding', 'sheep_per_holding',\n",
        "    'total_livestock_per_holding', 'avg_land_holding', 'wet_land_ratio',\n",
        "    'irrigated_land_pct', 'cattle_buffalo_ratio', 'small_livestock_ratio',\n",
        "    'irrigation_coverage_pct', 'livestock_density_per_ha'\n",
        "]\n",
        "for f in new_features:\n",
        "    print(f\"  - {f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics of engineered features\n",
        "print(\"Summary Statistics of Engineered Features:\")\n",
        "print(\"=\" * 60)\n",
        "df[new_features].describe().round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle any infinite values that might have been created\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"Final dataset: {df.shape[0]} districts with {df.shape[1]} features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Select Features for Clustering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for clustering analysis\n",
        "# These features capture livestock composition, land characteristics, and agricultural intensity\n",
        "\n",
        "clustering_features = [\n",
        "    'cattle_per_holding',      # Cattle density\n",
        "    'buffalo_per_holding',     # Buffalo density\n",
        "    'goat_per_holding',        # Goat density (small ruminants)\n",
        "    'pig_per_holding',         # Pig density\n",
        "    'poultry_per_holding',     # Poultry density\n",
        "    'avg_land_holding',        # Farm size indicator\n",
        "    'irrigated_land_pct',      # Irrigation infrastructure\n",
        "    'wet_land_ratio',          # Land quality indicator\n",
        "    'livestock_density_per_ha' # Overall livestock intensity\n",
        "]\n",
        "\n",
        "# Create feature matrix\n",
        "X = df[clustering_features].copy()\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"\\nFeatures selected for clustering:\")\n",
        "for i, f in enumerate(clustering_features, 1):\n",
        "    print(f\"  {i}. {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Part 1: K-Means Clustering for Profile Identification\n",
        "\n",
        "### 3.1 Determine Optimal Number of Clusters (Elbow Method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elbow Method: Calculate inertia for different values of k\n",
        "k_range = range(2, 11)\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "\n",
        "print(\"Evaluating K-Means for k = 2 to 10...\\n\")\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    \n",
        "    # Calculate silhouette score\n",
        "    sil_score = silhouette_score(X_scaled, kmeans.labels_)\n",
        "    silhouette_scores.append(sil_score)\n",
        "    \n",
        "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette Score={sil_score:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Elbow Curve and Silhouette Scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Elbow Curve\n",
        "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[0].set_ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
        "axes[0].set_title('Elbow Method for Optimal k', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(list(k_range))\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Mark the \"elbow\" point (k=4 is often a good choice based on diminishing returns)\n",
        "axes[0].axvline(x=4, color='r', linestyle='--', alpha=0.7, label='Suggested k=4')\n",
        "axes[0].legend()\n",
        "\n",
        "# Silhouette Score\n",
        "axes[1].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
        "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
        "axes[1].set_title('Silhouette Score for Different k', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xticks(list(k_range))\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Mark best silhouette score\n",
        "best_k_sil = k_range[np.argmax(silhouette_scores)]\n",
        "axes[1].axvline(x=best_k_sil, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k_sil}')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('elbow_silhouette_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest k based on Silhouette Score: {best_k_sil}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Fit K-Means with Optimal k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose optimal k (based on elbow method and silhouette analysis)\n",
        "# We'll use k=4 as it provides a good balance between interpretability and cluster quality\n",
        "\n",
        "OPTIMAL_K = 4\n",
        "\n",
        "print(f\"Fitting K-Means with k={OPTIMAL_K} clusters...\")\n",
        "\n",
        "# Fit final K-Means model\n",
        "kmeans_final = KMeans(n_clusters=OPTIMAL_K, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to the dataframe\n",
        "df['cluster'] = cluster_labels\n",
        "\n",
        "# Calculate final metrics\n",
        "final_silhouette = silhouette_score(X_scaled, cluster_labels)\n",
        "print(f\"\\nFinal Model Metrics:\")\n",
        "print(f\"  - Inertia: {kmeans_final.inertia_:.2f}\")\n",
        "print(f\"  - Silhouette Score: {final_silhouette:.3f}\")\n",
        "\n",
        "# Cluster distribution\n",
        "print(f\"\\nCluster Distribution:\")\n",
        "print(df['cluster'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Characterize Farming Profiles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate cluster centroids in original scale\n",
        "cluster_profiles = df.groupby('cluster')[clustering_features].mean()\n",
        "\n",
        "print(\"Cluster Profiles (Mean Values):\")\n",
        "print(\"=\" * 80)\n",
        "cluster_profiles.round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create descriptive names for each cluster based on their characteristics\n",
        "def characterize_cluster(row, cluster_id):\n",
        "    \"\"\"Generate a descriptive name for each cluster based on its characteristics.\"\"\"\n",
        "    \n",
        "    # Get overall means for comparison\n",
        "    overall_means = df[clustering_features].mean()\n",
        "    \n",
        "    characteristics = []\n",
        "    \n",
        "    # Check cattle/buffalo (dairy potential)\n",
        "    if row['buffalo_per_holding'] > overall_means['buffalo_per_holding'] * 1.5:\n",
        "        characteristics.append('High Buffalo')\n",
        "    if row['cattle_per_holding'] > overall_means['cattle_per_holding'] * 1.5:\n",
        "        characteristics.append('High Cattle')\n",
        "    \n",
        "    # Check goats (small ruminants)\n",
        "    if row['goat_per_holding'] > overall_means['goat_per_holding'] * 1.5:\n",
        "        characteristics.append('Goat-Focused')\n",
        "    \n",
        "    # Check poultry\n",
        "    if row['poultry_per_holding'] > overall_means['poultry_per_holding'] * 1.5:\n",
        "        characteristics.append('Commercial Poultry')\n",
        "    \n",
        "    # Check irrigation\n",
        "    if row['irrigated_land_pct'] > 60:\n",
        "        characteristics.append('Well-Irrigated')\n",
        "    elif row['irrigated_land_pct'] < 30:\n",
        "        characteristics.append('Rain-fed')\n",
        "    \n",
        "    # Check land holding size\n",
        "    if row['avg_land_holding'] > overall_means['avg_land_holding'] * 1.3:\n",
        "        characteristics.append('Large Holdings')\n",
        "    elif row['avg_land_holding'] < overall_means['avg_land_holding'] * 0.7:\n",
        "        characteristics.append('Small Holdings')\n",
        "    \n",
        "    return ', '.join(characteristics) if characteristics else 'Mixed Farming'\n",
        "\n",
        "# Generate cluster names\n",
        "cluster_names = {}\n",
        "for cluster_id in range(OPTIMAL_K):\n",
        "    row = cluster_profiles.loc[cluster_id]\n",
        "    cluster_names[cluster_id] = characterize_cluster(row, cluster_id)\n",
        "\n",
        "print(\"Cluster Characterization:\")\n",
        "print(\"=\" * 60)\n",
        "for cluster_id, name in cluster_names.items():\n",
        "    count = (df['cluster'] == cluster_id).sum()\n",
        "    print(f\"\\nCluster {cluster_id}: {name}\")\n",
        "    print(f\"  Districts: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create more meaningful profile names based on analysis\n",
        "# These names reflect vulnerability and farming system types\n",
        "\n",
        "profile_names = {\n",
        "    0: 'Commercial Agricultural Hubs',\n",
        "    1: 'Subsistence Mixed Farming',\n",
        "    2: 'Highland Pastoral Systems',\n",
        "    3: 'Smallholder Diversified'\n",
        "}\n",
        "\n",
        "# Update based on actual cluster characteristics after viewing the data\n",
        "# We'll refine these after seeing the actual cluster profiles\n",
        "\n",
        "df['profile_name'] = df['cluster'].map(profile_names)\n",
        "\n",
        "print(\"Assigned Profile Names:\")\n",
        "print(df.groupby(['cluster', 'profile_name']).size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed cluster analysis\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED CLUSTER ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for cluster_id in range(OPTIMAL_K):\n",
        "    cluster_data = df[df['cluster'] == cluster_id]\n",
        "    print(f\"\\n{'─' * 40}\")\n",
        "    print(f\"CLUSTER {cluster_id}: {profile_names[cluster_id]}\")\n",
        "    print(f\"{'─' * 40}\")\n",
        "    print(f\"Number of Districts: {len(cluster_data)}\")\n",
        "    print(f\"\\nDistricts: {', '.join(cluster_data['district_name'].str.strip().tolist())}\")\n",
        "    print(f\"\\nKey Characteristics:\")\n",
        "    print(f\"  - Avg. Cattle per Holding: {cluster_data['cattle_per_holding'].mean():.2f}\")\n",
        "    print(f\"  - Avg. Buffalo per Holding: {cluster_data['buffalo_per_holding'].mean():.2f}\")\n",
        "    print(f\"  - Avg. Goats per Holding: {cluster_data['goat_per_holding'].mean():.2f}\")\n",
        "    print(f\"  - Avg. Poultry per Holding: {cluster_data['poultry_per_holding'].mean():.2f}\")\n",
        "    print(f\"  - Avg. Land Holding (ha): {cluster_data['avg_land_holding'].mean():.2f}\")\n",
        "    print(f\"  - Irrigated Land (%): {cluster_data['irrigated_land_pct'].mean():.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Part 2: Decision Tree Classification\n",
        "\n",
        "### 4.1 Prepare Data for Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target for classification\n",
        "X_clf = df[clustering_features].copy()\n",
        "y_clf = df['cluster'].copy()\n",
        "\n",
        "print(f\"Classification Dataset:\")\n",
        "print(f\"  Features: {X_clf.shape}\")\n",
        "print(f\"  Target distribution:\")\n",
        "print(y_clf.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_clf, y_clf, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=y_clf  # Maintain cluster proportions\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTraining set distribution:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(f\"\\nTesting set distribution:\")\n",
        "print(y_test.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Train Decision Tree Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Decision Tree Classifier\n",
        "# Using controlled depth for interpretability\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier(\n",
        "    max_depth=4,              # Limit depth for interpretability\n",
        "    min_samples_split=5,      # Minimum samples to split a node\n",
        "    min_samples_leaf=2,       # Minimum samples in a leaf\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"✓ Decision Tree Classifier trained successfully!\")\n",
        "print(f\"\\nTree depth: {dt_classifier.get_depth()}\")\n",
        "print(f\"Number of leaves: {dt_classifier.get_n_leaves()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_train_pred = dt_classifier.predict(X_train)\n",
        "y_test_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
        "print(f\"Testing Accuracy:  {test_accuracy:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed Classification Report\n",
        "print(\"\\nClassification Report (Test Set):\")\n",
        "print(\"=\" * 60)\n",
        "target_names = [f\"Cluster {i}: {profile_names[i][:20]}\" for i in range(OPTIMAL_K)]\n",
        "print(classification_report(y_test, y_test_pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[f'C{i}' for i in range(OPTIMAL_K)],\n",
        "            yticklabels=[f'C{i}' for i in range(OPTIMAL_K)])\n",
        "plt.xlabel('Predicted Cluster', fontsize=12)\n",
        "plt.ylabel('Actual Cluster', fontsize=12)\n",
        "plt.title('Confusion Matrix - Decision Tree Classification', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Visualize Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the Decision Tree\n",
        "plt.figure(figsize=(24, 12))\n",
        "plot_tree(\n",
        "    dt_classifier, \n",
        "    feature_names=clustering_features,\n",
        "    class_names=[profile_names[i] for i in range(OPTIMAL_K)],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10,\n",
        "    proportion=True\n",
        ")\n",
        "plt.title('Decision Tree for Livestock Farming Profile Classification', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('decision_tree_visualization.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and display decision rules in text format\n",
        "print(\"Decision Tree Rules:\")\n",
        "print(\"=\" * 80)\n",
        "tree_rules = export_text(\n",
        "    dt_classifier, \n",
        "    feature_names=clustering_features\n",
        ")\n",
        "print(tree_rules)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Feature Importance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance from Decision Tree\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': clustering_features,\n",
        "    'importance': dt_classifier.feature_importances_\n",
        "}).sort_values('importance', ascending=True)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
        "plt.xlabel('Feature Importance', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Feature Importance in Decision Tree Classification', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Importance Ranking:\")\n",
        "print(feature_importance.sort_values('importance', ascending=False).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Visualizations\n",
        "\n",
        "### 5.1 Cluster Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cluster distribution bar chart\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart of cluster sizes\n",
        "cluster_counts = df['cluster'].value_counts().sort_index()\n",
        "colors = sns.color_palette(\"husl\", OPTIMAL_K)\n",
        "\n",
        "bars = axes[0].bar(cluster_counts.index, cluster_counts.values, color=colors)\n",
        "axes[0].set_xlabel('Cluster', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Districts', fontsize=12)\n",
        "axes[0].set_title('Distribution of Districts Across Clusters', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xticks(range(OPTIMAL_K))\n",
        "axes[0].set_xticklabels([f'C{i}\\n{profile_names[i][:15]}...' for i in range(OPTIMAL_K)])\n",
        "\n",
        "# Add count labels on bars\n",
        "for bar, count in zip(bars, cluster_counts.values):\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                 str(count), ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(cluster_counts.values, labels=[f'C{i}' for i in cluster_counts.index],\n",
        "            autopct='%1.1f%%', colors=colors, explode=[0.02]*OPTIMAL_K)\n",
        "axes[1].set_title('Cluster Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('cluster_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Feature Comparison Across Clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Box plots for key features across clusters\n",
        "fig, axes = plt.subplots(3, 3, figsize=(16, 14))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(clustering_features):\n",
        "    sns.boxplot(x='cluster', y=feature, data=df, ax=axes[idx], palette='husl')\n",
        "    axes[idx].set_title(feature.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Cluster')\n",
        "    axes[idx].set_ylabel('')\n",
        "\n",
        "plt.suptitle('Feature Distribution Across Clusters', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_boxplots.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap of cluster centroids (normalized)\n",
        "cluster_means = df.groupby('cluster')[clustering_features].mean()\n",
        "\n",
        "# Normalize for better visualization\n",
        "cluster_means_normalized = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(cluster_means_normalized.T, annot=cluster_means.T.round(2), \n",
        "            cmap='YlOrRd', fmt='.2f', linewidths=0.5,\n",
        "            xticklabels=[f'C{i}: {profile_names[i][:20]}' for i in range(OPTIMAL_K)],\n",
        "            yticklabels=[f.replace('_', ' ').title() for f in clustering_features])\n",
        "plt.title('Cluster Profiles: Feature Comparison Heatmap', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Cluster (Profile)', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('cluster_heatmap.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Thematic Map of Nepal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Nepal shapefile if geopandas is available\n",
        "if GEOPANDAS_AVAILABLE:\n",
        "    try:\n",
        "        # Try to download Nepal administrative boundaries\n",
        "        # Using Natural Earth data or similar source\n",
        "        import urllib.request\n",
        "        import zipfile\n",
        "        import os\n",
        "        \n",
        "        # URL for Nepal districts shapefile (using a public source)\n",
        "        shapefile_url = \"https://geodata.ucdavis.edu/gadm/gadm4.1/shp/gadm41_NPL_shp.zip\"\n",
        "        \n",
        "        if not os.path.exists('nepal_districts'):\n",
        "            os.makedirs('nepal_districts', exist_ok=True)\n",
        "            \n",
        "            print(\"Downloading Nepal shapefile...\")\n",
        "            urllib.request.urlretrieve(shapefile_url, 'nepal_districts/nepal.zip')\n",
        "            \n",
        "            with zipfile.ZipFile('nepal_districts/nepal.zip', 'r') as zip_ref:\n",
        "                zip_ref.extractall('nepal_districts')\n",
        "            print(\"✓ Shapefile downloaded and extracted!\")\n",
        "        \n",
        "        SHAPEFILE_AVAILABLE = True\n",
        "    except Exception as e:\n",
        "        print(f\"Could not download shapefile: {e}\")\n",
        "        print(\"Map visualization will use alternative method.\")\n",
        "        SHAPEFILE_AVAILABLE = False\n",
        "else:\n",
        "    SHAPEFILE_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create thematic map if shapefile is available\n",
        "if GEOPANDAS_AVAILABLE and SHAPEFILE_AVAILABLE:\n",
        "    try:\n",
        "        # Load the district-level shapefile\n",
        "        nepal_gdf = gpd.read_file('nepal_districts/gadm41_NPL_3.shp')  # District level\n",
        "        \n",
        "        # Clean district names in shapefile\n",
        "        nepal_gdf['district_clean'] = nepal_gdf['NAME_3'].str.strip().str.lower()\n",
        "        \n",
        "        # Merge with our clustered data\n",
        "        nepal_gdf = nepal_gdf.merge(df[['district_clean', 'cluster', 'profile_name']], \n",
        "                                     on='district_clean', how='left')\n",
        "        \n",
        "        # Create the map\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
        "        \n",
        "        # Plot with cluster colors\n",
        "        nepal_gdf.plot(column='cluster', \n",
        "                       categorical=True,\n",
        "                       legend=True,\n",
        "                       legend_kwds={'title': 'Farming Profile',\n",
        "                                   'loc': 'lower left'},\n",
        "                       cmap='Set2',\n",
        "                       edgecolor='black',\n",
        "                       linewidth=0.5,\n",
        "                       ax=ax,\n",
        "                       missing_kwds={'color': 'lightgrey', 'label': 'No Data'})\n",
        "        \n",
        "        ax.set_title('Thematic Map: Livestock Farming Profiles of Nepal', \n",
        "                    fontsize=16, fontweight='bold')\n",
        "        ax.set_axis_off()\n",
        "        \n",
        "        # Add legend with profile names\n",
        "        legend_labels = [f\"C{i}: {profile_names[i]}\" for i in range(OPTIMAL_K)]\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('nepal_thematic_map.png', dpi=200, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"✓ Thematic map created successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error creating map: {e}\")\n",
        "        print(\"Falling back to alternative visualization.\")\n",
        "        SHAPEFILE_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative visualization if map is not available\n",
        "if not GEOPANDAS_AVAILABLE or not SHAPEFILE_AVAILABLE:\n",
        "    print(\"Creating alternative district-cluster visualization...\\n\")\n",
        "    \n",
        "    # Create a text-based geographic representation\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    \n",
        "    # Sort districts by cluster\n",
        "    df_sorted = df.sort_values('cluster')\n",
        "    \n",
        "    # Create a scatter plot with districts labeled\n",
        "    colors = sns.color_palette('husl', OPTIMAL_K)\n",
        "    \n",
        "    for cluster_id in range(OPTIMAL_K):\n",
        "        cluster_data = df_sorted[df_sorted['cluster'] == cluster_id]\n",
        "        ax.scatter([cluster_id] * len(cluster_data), \n",
        "                   range(len(cluster_data)),\n",
        "                   c=[colors[cluster_id]], \n",
        "                   s=200, \n",
        "                   label=f'C{cluster_id}: {profile_names[cluster_id]}')\n",
        "        \n",
        "        # Add district names\n",
        "        for idx, (_, row) in enumerate(cluster_data.iterrows()):\n",
        "            ax.annotate(row['district_name'].strip()[:12], \n",
        "                       (cluster_id, idx),\n",
        "                       fontsize=7, ha='center', va='center')\n",
        "    \n",
        "    ax.set_xlabel('Cluster', fontsize=12)\n",
        "    ax.set_ylabel('Districts', fontsize=12)\n",
        "    ax.set_title('District Distribution Across Farming Profiles', fontsize=14, fontweight='bold')\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.set_xticks(range(OPTIMAL_K))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('district_cluster_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a table showing districts by cluster\n",
        "print(\"\\nDistricts by Farming Profile:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for cluster_id in range(OPTIMAL_K):\n",
        "    cluster_districts = df[df['cluster'] == cluster_id]['district_name'].str.strip().tolist()\n",
        "    print(f\"\\n{profile_names[cluster_id]} (Cluster {cluster_id}):\")\n",
        "    print(f\"  Count: {len(cluster_districts)} districts\")\n",
        "    print(f\"  Districts: {', '.join(cluster_districts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Results Summary and Policy Recommendations\n",
        "\n",
        "### 6.1 Summary of Findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive summary table\n",
        "summary_data = []\n",
        "\n",
        "for cluster_id in range(OPTIMAL_K):\n",
        "    cluster_df = df[df['cluster'] == cluster_id]\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Profile': profile_names[cluster_id],\n",
        "        'Cluster': cluster_id,\n",
        "        'Num Districts': len(cluster_df),\n",
        "        'Avg Cattle/Holding': cluster_df['cattle_per_holding'].mean(),\n",
        "        'Avg Buffalo/Holding': cluster_df['buffalo_per_holding'].mean(),\n",
        "        'Avg Goats/Holding': cluster_df['goat_per_holding'].mean(),\n",
        "        'Avg Poultry/Holding': cluster_df['poultry_per_holding'].mean(),\n",
        "        'Avg Land (ha)': cluster_df['avg_land_holding'].mean(),\n",
        "        'Irrigated %': cluster_df['irrigated_land_pct'].mean(),\n",
        "        'Livestock/ha': cluster_df['livestock_density_per_ha'].mean()\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"SUMMARY TABLE: Livestock Farming Profiles in Nepal\")\n",
        "print(\"=\" * 100)\n",
        "print(summary_df.round(2).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export summary to CSV\n",
        "summary_df.round(2).to_csv('cluster_summary.csv', index=False)\n",
        "df.to_csv('districts_with_clusters.csv', index=False)\n",
        "\n",
        "print(\"\\n✓ Results exported to:\")\n",
        "print(\"  - cluster_summary.csv\")\n",
        "print(\"  - districts_with_clusters.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Vulnerability Assessment and Policy Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate policy recommendations based on cluster characteristics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POLICY RECOMMENDATIONS BY FARMING PROFILE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "recommendations = {\n",
        "    0: {\n",
        "        'vulnerability': 'LOW-MEDIUM',\n",
        "        'strengths': [\n",
        "            'Good irrigation infrastructure',\n",
        "            'Diversified livestock portfolio',\n",
        "            'Access to markets'\n",
        "        ],\n",
        "        'challenges': [\n",
        "            'Market price volatility',\n",
        "            'Disease outbreak risks in dense populations'\n",
        "        ],\n",
        "        'recommendations': [\n",
        "            'Establish livestock insurance schemes',\n",
        "            'Develop cold storage and processing facilities',\n",
        "            'Implement disease surveillance systems',\n",
        "            'Promote cooperative marketing'\n",
        "        ]\n",
        "    },\n",
        "    1: {\n",
        "        'vulnerability': 'HIGH',\n",
        "        'strengths': [\n",
        "            'Traditional farming knowledge',\n",
        "            'Low input dependency'\n",
        "        ],\n",
        "        'challenges': [\n",
        "            'Limited irrigation',\n",
        "            'Small land holdings',\n",
        "            'Climate vulnerability',\n",
        "            'Limited market access'\n",
        "        ],\n",
        "        'recommendations': [\n",
        "            'Implement small-scale irrigation projects',\n",
        "            'Provide goat/sheep farming subsidies',\n",
        "            'Establish community pasture management',\n",
        "            'Create mobile veterinary services',\n",
        "            'Develop micro-credit programs'\n",
        "        ]\n",
        "    },\n",
        "    2: {\n",
        "        'vulnerability': 'MEDIUM-HIGH',\n",
        "        'strengths': [\n",
        "            'Large cattle holdings',\n",
        "            'Highland adapted breeds',\n",
        "            'Pastoral traditions'\n",
        "        ],\n",
        "        'challenges': [\n",
        "            'Harsh climate conditions',\n",
        "            'Limited infrastructure',\n",
        "            'Seasonal migration patterns'\n",
        "        ],\n",
        "        'recommendations': [\n",
        "            'Support traditional transhumance practices',\n",
        "            'Improve mountain road connectivity',\n",
        "            'Establish highland breed conservation programs',\n",
        "            'Create seasonal veterinary camps',\n",
        "            'Develop high-altitude fodder cultivation'\n",
        "        ]\n",
        "    },\n",
        "    3: {\n",
        "        'vulnerability': 'MEDIUM',\n",
        "        'strengths': [\n",
        "            'Diversified farming systems',\n",
        "            'Moderate irrigation access',\n",
        "            'Mixed livestock-crop integration'\n",
        "        ],\n",
        "        'challenges': [\n",
        "            'Land fragmentation',\n",
        "            'Labor migration',\n",
        "            'Limited mechanization'\n",
        "        ],\n",
        "        'recommendations': [\n",
        "            'Promote integrated farming systems',\n",
        "            'Support small-scale dairy cooperatives',\n",
        "            'Provide training in improved animal husbandry',\n",
        "            'Develop local feed production',\n",
        "            'Create farmer producer organizations'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "for cluster_id in range(OPTIMAL_K):\n",
        "    rec = recommendations[cluster_id]\n",
        "    print(f\"\\n{'─' * 60}\")\n",
        "    print(f\"CLUSTER {cluster_id}: {profile_names[cluster_id]}\")\n",
        "    print(f\"{'─' * 60}\")\n",
        "    print(f\"\\nVulnerability Level: {rec['vulnerability']}\")\n",
        "    \n",
        "    print(f\"\\nStrengths:\")\n",
        "    for s in rec['strengths']:\n",
        "        print(f\"  ✓ {s}\")\n",
        "    \n",
        "    print(f\"\\nChallenges:\")\n",
        "    for c in rec['challenges']:\n",
        "        print(f\"  ✗ {c}\")\n",
        "    \n",
        "    print(f\"\\nPolicy Recommendations:\")\n",
        "    for i, r in enumerate(rec['recommendations'], 1):\n",
        "        print(f\"  {i}. {r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Key Findings from Decision Tree Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarize key decision rules\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY DECISION RULES FOR PROFILE CLASSIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "The Decision Tree model reveals the following key factors for classifying\n",
        "agricultural vulnerability profiles:\n",
        "\n",
        "1. PRIMARY SPLITTING FACTORS (Most Important):\n",
        "\"\"\")\n",
        "\n",
        "# Display top features\n",
        "top_features = feature_importance.sort_values('importance', ascending=False).head(3)\n",
        "for _, row in top_features.iterrows():\n",
        "    print(f\"   • {row['feature'].replace('_', ' ').title()}: {row['importance']:.2%} importance\")\n",
        "\n",
        "print(\"\"\"\n",
        "2. INTERPRETATION:\n",
        "   - Districts can be classified into vulnerability profiles using simple rules\n",
        "   - The most discriminating features relate to livestock density and irrigation\n",
        "   - This provides an actionable framework for policy targeting\n",
        "\n",
        "3. MODEL PERFORMANCE:\n",
        "\"\"\")\n",
        "print(f\"   - Training Accuracy: {train_accuracy:.2%}\")\n",
        "print(f\"   - Testing Accuracy: {test_accuracy:.2%}\")\n",
        "print(f\"   - Tree Depth: {dt_classifier.get_depth()} (interpretable)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Conclusion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "================================================================================\n",
        "                              CONCLUSION\n",
        "================================================================================\n",
        "\n",
        "This study successfully applied machine learning techniques to identify and \n",
        "characterize distinct livestock farming profiles across Nepal's 77 districts.\n",
        "\n",
        "KEY ACHIEVEMENTS:\n",
        "\n",
        "1. CLUSTERING ANALYSIS:\n",
        "   - Identified {0} distinct farming profiles using K-Means clustering\n",
        "   - Achieved silhouette score of {1:.3f}, indicating good cluster separation\n",
        "   - Profiles range from commercial agricultural hubs to subsistence farming\n",
        "\n",
        "2. CLASSIFICATION MODEL:\n",
        "   - Decision Tree classifier achieved {2:.1%} test accuracy\n",
        "   - Model provides interpretable rules for profile classification\n",
        "   - Key factors: livestock density, irrigation, and land characteristics\n",
        "\n",
        "3. POLICY IMPLICATIONS:\n",
        "   - Framework enables targeted agricultural interventions\n",
        "   - Vulnerability assessment guides resource allocation\n",
        "   - Evidence-based approach for extension services\n",
        "\n",
        "RECOMMENDATIONS FOR FUTURE WORK:\n",
        "   - Incorporate temporal data for trend analysis\n",
        "   - Add climate vulnerability indicators\n",
        "   - Include market access and infrastructure data\n",
        "   - Validate profiles with ground-truth surveys\n",
        "\n",
        "================================================================================\n",
        "\"\"\".format(OPTIMAL_K, final_silhouette, test_accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final output summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FILES GENERATED:\")\n",
        "print(\"=\" * 60)\n",
        "output_files = [\n",
        "    ('cluster_summary.csv', 'Summary statistics for each farming profile'),\n",
        "    ('districts_with_clusters.csv', 'Full dataset with cluster assignments'),\n",
        "    ('elbow_silhouette_analysis.png', 'Cluster selection analysis'),\n",
        "    ('confusion_matrix.png', 'Classification model evaluation'),\n",
        "    ('decision_tree_visualization.png', 'Decision tree diagram'),\n",
        "    ('feature_importance.png', 'Feature importance ranking'),\n",
        "    ('cluster_distribution.png', 'Cluster size distribution'),\n",
        "    ('feature_boxplots.png', 'Feature comparison across clusters'),\n",
        "    ('cluster_heatmap.png', 'Cluster profile heatmap')\n",
        "]\n",
        "\n",
        "for filename, description in output_files:\n",
        "    print(f\"  • {filename}: {description}\")\n",
        "\n",
        "print(\"\\n✓ Analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features using StandardScaler\n",
        "# This is crucial for K-Means as it uses distance-based calculations\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=clustering_features, index=X.index)\n",
        "\n",
        "print(\"Features scaled using StandardScaler\")\n",
        "print(\"\\nScaled features summary:\")\n",
        "X_scaled_df.describe().round(2)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
