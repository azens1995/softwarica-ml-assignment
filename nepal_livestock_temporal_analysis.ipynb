{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Analysis: 50 Years of Livestock Farming in Nepal (1972-2021)\n",
    "\n",
    "## Synthetic Historical Data Generation and Trend Analysis\n",
    "\n",
    "**Author:** ML Assignment Project  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook extends the livestock farming vulnerability analysis by:\n",
    "1. **Generating synthetic historical data** for 50 years (1972-2021) based on 2021 baseline\n",
    "2. **Analyzing temporal trends** in agricultural practices across Nepal's districts\n",
    "3. **Identifying structural changes** in farming systems over time\n",
    "4. **Clustering evolution** - how farming profiles have changed over decades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Installation\n",
    "\n",
    "### 1.1 Install Required Libraries (for Google Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (for Google Colab)\n",
    "%pip install geopandas folium mapclassify -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    silhouette_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Geographic visualization (optional - will handle gracefully if not available)\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    GEOPANDAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GEOPANDAS_AVAILABLE = False\n",
    "    print(\"Note: geopandas not available. Map visualizations will be skipped.\")\n",
    "    print(\"Install with: pip install geopandas\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load 2021 Baseline Data from Files\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment and set up data loading\n",
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "IN_COLAB = 'google.colab' in str(get_ipython()) if 'get_ipython' in dir() else False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab environment\")\n",
    "else:\n",
    "    print(\"Running in local environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "# Update these paths according to your setup\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Select/upload CSV files in Colab (file picker)\n",
    "    from google.colab import files\n",
    "    print(\"Please select the three CSV files (you can multi-select):\")\n",
    "    print(\"  - table-1.-number-of-holdings-and-area-by-district-.csv\")\n",
    "    print(\"  - table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv\")\n",
    "    print(\"  - table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    def pick_file(keyword, fallback=None):\n",
    "        for fname in uploaded.keys():\n",
    "            if keyword.lower() in fname.lower():\n",
    "                return fname\n",
    "        if fallback and fallback in uploaded:\n",
    "            return fallback\n",
    "        return list(uploaded.keys())[0]\n",
    "\n",
    "    holdings_area_path = pick_file('holdings-and-area', 'table-1.-number-of-holdings-and-area-by-district-.csv')\n",
    "    irrigation_path = pick_file('irrigation', 'table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv')\n",
    "    livestock_path = pick_file('livestocks-and-poultry', 'table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv')\n",
    "\n",
    "    print(f\"Using files -> holdings: {holdings_area_path}, irrigation: {irrigation_path}, livestock: {livestock_path}\")\n",
    "else:\n",
    "    # Local paths - update as needed\n",
    "    base_path = '/Users/eklakdangaura/College/ML/Assignment/Datasets/'\n",
    "    holdings_area_path = base_path + 'table-1.-number-of-holdings-and-area-by-district-.csv'\n",
    "    irrigation_path = base_path + 'table-4.1.-number-area-number-of-holdings-reporting-and-area-irrigated-by-source-of-irrigation-a.csv'\n",
    "    livestock_path = base_path + 'table-17.-number-of-holdings-livestocks-and-poultry-by-districts.csv'\n",
    "\n",
    "print(\"File paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three datasets from CSV files\n",
    "print(\"Loading datasets from files...\")\n",
    "\n",
    "# Dataset 1: Holdings and Area by District\n",
    "df_land = pd.read_csv(holdings_area_path, sep='\\t')\n",
    "print(f\"1. Holdings & Area Dataset: {df_land.shape[0]} rows, {df_land.shape[1]} columns\")\n",
    "\n",
    "# Dataset 2: Irrigation Data\n",
    "df_irr = pd.read_csv(irrigation_path, sep='\\t')\n",
    "print(f\"2. Irrigation Dataset: {df_irr.shape[0]} rows, {df_irr.shape[1]} columns\")\n",
    "\n",
    "# Dataset 3: Livestock Data\n",
    "df_live = pd.read_csv(livestock_path)\n",
    "print(f\"3. Livestock Dataset: {df_live.shape[0]} rows, {df_live.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n✓ All datasets loaded successfully from files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Holdings & Area Dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 1: Holdings and Area by District\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape: {df_land.shape}\")\n",
    "print(f\"\\nColumns: {df_land.columns.tolist()}\")\n",
    "print(\"\\nData Types:\")\n",
    "print(df_land.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_land.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Irrigation Dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 2: Irrigation Data\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape: {df_irr.shape}\")\n",
    "print(f\"\\nColumns: {df_irr.columns.tolist()}\")\n",
    "print(\"\\nData Types:\")\n",
    "print(df_irr.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_irr.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Livestock Dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 3: Livestock Data\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape: {df_live.shape}\")\n",
    "print(f\"\\nColumns: {df_live.columns.tolist()}\")\n",
    "print(\"\\nData Types:\")\n",
    "print(df_live.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_live.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics for all datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. Holdings & Area Dataset Statistics:\")\n",
    "display(df_land.describe())\n",
    "\n",
    "print(\"\\n2. Irrigation Dataset Statistics:\")\n",
    "display(df_irr.describe())\n",
    "\n",
    "print(\"\\n3. Livestock Dataset Statistics:\")\n",
    "display(df_live.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Preprocessing and District Name Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize district names and merge datasets\n",
    "def standardize_district_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    return str(name).strip().lower()\n",
    "\n",
    "# Clean district names\n",
    "df_land['district_clean'] = df_land['Districts'].apply(standardize_district_name)\n",
    "df_irr['district_clean'] = df_irr['Districts'].apply(standardize_district_name)\n",
    "df_live['district_clean'] = df_live['District'].apply(standardize_district_name)\n",
    "\n",
    "# Select relevant columns\n",
    "df_land_select = df_land[['district_clean', 'Districts', 'Number of holdings', \n",
    "                          'Total wet  area (ha)', 'Total dry  area (ha)', 'Total  area (ha)']].copy()\n",
    "df_land_select.columns = ['district_clean', 'Districts', 'Number of holdings', \n",
    "                          'wet_area_ha', 'dry_area_ha', 'total_area_ha']\n",
    "\n",
    "df_irr_select = df_irr[['district_clean', 'No. of holdings reporting irrigation', \n",
    "                        'Total area (ha) of irrigation']].copy()\n",
    "df_irr_select.columns = ['district_clean', 'holdings_with_irrigation', 'irrigated_area_ha']\n",
    "\n",
    "# Handle livestock columns\n",
    "livestock_cols = ['district_clean', 'Total number of holdings', 'Number of holdings reporting livestock',\n",
    "                  'No. of  cattles', 'No. of buffalo', 'No. of goat/chyangra', \n",
    "                  'No. of pigs/boar', 'No. of poultry(chicken)', 'No. of sheep']\n",
    "df_live_select = df_live[livestock_cols].copy()\n",
    "df_live_select.columns = ['district_clean', 'total_holdings_livestock', 'holdings_with_livestock',\n",
    "                          'num_cattle', 'num_buffalo', 'num_goats', 'num_pigs', 'num_poultry', 'num_sheep']\n",
    "\n",
    "# Fill missing values\n",
    "for col in df_live_select.columns:\n",
    "    if col != 'district_clean':\n",
    "        df_live_select[col] = pd.to_numeric(df_live_select[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Merge all datasets\n",
    "df_merged = df_land_select.merge(df_irr_select, on='district_clean', how='outer').merge(\n",
    "    df_live_select, on='district_clean', how='outer')\n",
    "\n",
    "# Fill any remaining missing values\n",
    "numeric_cols = df_merged.select_dtypes(include=[np.number]).columns\n",
    "df_merged[numeric_cols] = df_merged[numeric_cols].fillna(0)\n",
    "\n",
    "print(f\"Merged dataset: {df_merged.shape[0]} districts, {df_merged.shape[1]} columns\")\n",
    "print(f\"\\nColumns: {df_merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for district name mismatches across datasets\n",
    "holdings_districts = set(df_land['district_clean'].dropna())\n",
    "irrigation_districts = set(df_irr['district_clean'].dropna())\n",
    "livestock_districts = set(df_live['district_clean'].dropna())\n",
    "\n",
    "# Find common districts\n",
    "common_districts = holdings_districts & irrigation_districts & livestock_districts\n",
    "print(f\"District Name Verification:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Holdings dataset: {len(holdings_districts)} districts\")\n",
    "print(f\"Irrigation dataset: {len(irrigation_districts)} districts\")\n",
    "print(f\"Livestock dataset: {len(livestock_districts)} districts\")\n",
    "print(f\"\\nCommon districts across all datasets: {len(common_districts)}\")\n",
    "\n",
    "# Check for mismatches\n",
    "all_districts = holdings_districts | irrigation_districts | livestock_districts\n",
    "if len(all_districts) != len(common_districts):\n",
    "    print(\"\\n⚠️ Districts with potential mismatches:\")\n",
    "    only_holdings = holdings_districts - common_districts\n",
    "    only_irrigation = irrigation_districts - common_districts\n",
    "    only_livestock = livestock_districts - common_districts\n",
    "    \n",
    "    if only_holdings:\n",
    "        print(f\"  Only in Holdings: {only_holdings}\")\n",
    "    if only_irrigation:\n",
    "        print(f\"  Only in Irrigation: {only_irrigation}\")\n",
    "    if only_livestock:\n",
    "        print(f\"  Only in Livestock: {only_livestock}\")\n",
    "else:\n",
    "    print(\"\\n✓ All districts match across datasets!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Merge Datasets and Handle Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for 2021 baseline\n",
    "df_merged['Avg_Land_Size'] = df_merged['total_area_ha'] / df_merged['Number of holdings']\n",
    "df_merged['Pct_Irrigated'] = (df_merged['irrigated_area_ha'] / df_merged['total_area_ha']) * 100\n",
    "df_merged['Cattle_per_HH'] = df_merged['num_cattle'] / df_merged['Number of holdings']\n",
    "df_merged['Buffalo_per_HH'] = df_merged['num_buffalo'] / df_merged['Number of holdings']\n",
    "df_merged['Goat_per_HH'] = df_merged['num_goats'] / df_merged['Number of holdings']\n",
    "df_merged['Pig_per_HH'] = df_merged['num_pigs'] / df_merged['Number of holdings']\n",
    "df_merged['Poultry_per_HH'] = df_merged['num_poultry'] / df_merged['Number of holdings']\n",
    "\n",
    "# Handle infinite values\n",
    "df_merged = df_merged.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Create 2021 baseline\n",
    "base_cols = ['Districts', 'district_clean', 'Avg_Land_Size', 'Pct_Irrigated', \n",
    "             'Cattle_per_HH', 'Buffalo_per_HH', 'Goat_per_HH', 'Pig_per_HH', 'Poultry_per_HH']\n",
    "\n",
    "# Filter out rows without district name\n",
    "df_2021 = df_merged[base_cols].copy()\n",
    "df_2021 = df_2021.dropna(subset=['Districts'])\n",
    "df_2021['Year'] = 2021\n",
    "\n",
    "print(f\"2021 baseline dataset prepared: {df_2021.shape[0]} districts\")\n",
    "print(f\"\\n2021 Baseline Statistics:\")\n",
    "print(df_2021.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values after merge\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "missing = df_merged.isnull().sum()\n",
    "if missing.any():\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"✓ No missing values in merged dataset!\")\n",
    "\n",
    "print(f\"\\nMerged dataset shape: {df_merged.shape}\")\n",
    "print(f\"Number of districts: {df_merged['district_clean'].nunique()}\")\n",
    "print(\"\\nMerged dataset preview:\")\n",
    "display(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Feature Engineering and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Visualizations\n",
    "print(\"Visualizing Engineered Features for 2021 Baseline...\")\n",
    "\n",
    "# Define engineered features\n",
    "eng_features = ['Avg_Land_Size', 'Pct_Irrigated', 'Cattle_per_HH', 'Buffalo_per_HH', \n",
    "                'Goat_per_HH', 'Pig_per_HH', 'Poultry_per_HH']\n",
    "\n",
    "# 1. Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_2021[eng_features].corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, linewidths=0.5, square=True)\n",
    "plt.title('Correlation Matrix of Engineered Features (2021)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_feature_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Correlation heatmap saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Distribution of Key Features (2021 Baseline)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(eng_features):\n",
    "    sns.histplot(df_2021[feature], kde=True, ax=axes[idx], color='steelblue')\n",
    "    axes[idx].set_title(feature.replace('_', ' ').title(), fontweight='bold')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "# Turn off extra subplots\n",
    "for idx in range(len(eng_features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Distribution of Engineered Features (2021 Baseline)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Feature distributions saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pairplot for Key Livestock Features\n",
    "key_features = ['Cattle_per_HH', 'Buffalo_per_HH', 'Goat_per_HH', 'Poultry_per_HH']\n",
    "fig = sns.pairplot(df_2021[key_features], diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "fig.fig.suptitle('Pairwise Relationships: Livestock Features (2021)', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.savefig('temporal_pairplot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Pairplot saved\")\n",
    "\n",
    "print(\"\\n✓ Feature engineering visualizations complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Synthetic Historical Data (1972-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "all_years_data = [df_2021]\n",
    "current_df = df_2021.copy()\n",
    "\n",
    "print('Generating 50 years of synthetic data...')\n",
    "print('Trends: Poultry -8%/yr, Land +0.8%/yr, Irrigation -1%/yr, Pigs -2%/yr')\n",
    "\n",
    "for year in range(2020, 1971, -1):\n",
    "    new_df = current_df.copy()\n",
    "    new_df['Year'] = year\n",
    "    noise = np.random.uniform(0.98, 1.02, size=len(new_df))\n",
    "    \n",
    "    new_df['Poultry_per_HH'] = new_df['Poultry_per_HH'] * 0.92 * noise\n",
    "    new_df['Avg_Land_Size'] = new_df['Avg_Land_Size'] * 1.008 * noise\n",
    "    new_df['Pct_Irrigated'] = new_df['Pct_Irrigated'] * 0.99 * noise\n",
    "    new_df['Pig_per_HH'] = new_df['Pig_per_HH'] * 0.98 * noise\n",
    "    new_df['Goat_per_HH'] = new_df['Goat_per_HH'] * 1.001 * noise\n",
    "    new_df['Cattle_per_HH'] = new_df['Cattle_per_HH'] * 1.001 * noise\n",
    "    new_df['Buffalo_per_HH'] = new_df['Buffalo_per_HH'] * 1.001 * noise\n",
    "    \n",
    "    cols = new_df.select_dtypes(include=[np.number]).columns\n",
    "    new_df[cols] = new_df[cols].clip(lower=0)\n",
    "    \n",
    "    all_years_data.append(new_df)\n",
    "    current_df = new_df\n",
    "\n",
    "df_long = pd.concat(all_years_data, ignore_index=True)\n",
    "df_long = df_long.sort_values(['Districts', 'Year']).reset_index(drop=True)\n",
    "\n",
    "print(f'Generated {len(df_long)} rows (50 years x {len(df_2021)} districts)')\n",
    "df_long.to_csv('nepal_agriculture_50_years.csv', index=False)\n",
    "print('Exported to nepal_agriculture_50_years.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. National Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Avg_Land_Size', 'Pct_Irrigated', 'Cattle_per_HH', 'Buffalo_per_HH', 'Goat_per_HH', 'Pig_per_HH', 'Poultry_per_HH']\n",
    "national_trends = df_long.groupby('Year')[features].mean().reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(national_trends['Year'], national_trends[feature], linewidth=2, marker='o', markersize=2)\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_ylabel(feature.replace('_', ' '))\n",
    "    ax.set_title(feature.replace('_', ' ').title(), fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    z = np.polyfit(national_trends['Year'], national_trends[feature], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(national_trends['Year'], p(national_trends['Year']), '--r', alpha=0.7)\n",
    "\n",
    "for idx in range(len(features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Nepal Agricultural Trends: 1972-2021', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('national_trends_50years.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50-year change analysis\n",
    "year_1972 = national_trends[national_trends['Year'] == 1972].iloc[0]\n",
    "year_2021 = national_trends[national_trends['Year'] == 2021].iloc[0]\n",
    "\n",
    "print('50-YEAR CHANGE ANALYSIS (1972 -> 2021)')\n",
    "print('='*60)\n",
    "for feature in features:\n",
    "    val_1972 = year_1972[feature]\n",
    "    val_2021 = year_2021[feature]\n",
    "    pct_change = ((val_2021 - val_1972) / (val_1972 + 0.01)) * 100\n",
    "    direction = '+' if pct_change > 0 else ''\n",
    "    print(f'{feature}: 1972={val_1972:.2f} -> 2021={val_2021:.2f} ({direction}{pct_change:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Era-Based Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_era(year):\n",
    "    if year <= 1985:\n",
    "        return 'Era 1: Traditional (1972-1985)'\n",
    "    elif year <= 2000:\n",
    "        return 'Era 2: Early Modern (1986-2000)'\n",
    "    else:\n",
    "        return 'Era 3: Commercial (2001-2021)'\n",
    "\n",
    "df_long['Era'] = df_long['Year'].apply(assign_era)\n",
    "\n",
    "era_profiles = df_long.groupby(['Districts', 'Era'])[features].mean().reset_index()\n",
    "print('Era Profiles (National Averages):')\n",
    "print(era_profiles.groupby('Era')[features].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Determine Optimal Number of Clusters (Elbow Method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method and Silhouette Score Analysis\n",
    "clustering_features = ['Avg_Land_Size', 'Pct_Irrigated', 'Cattle_per_HH', 'Buffalo_per_HH', 'Goat_per_HH', 'Poultry_per_HH']\n",
    "\n",
    "df_2021_full = df_long[df_long['Year'] == 2021].copy()\n",
    "X = df_2021_full[clustering_features].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Calculate metrics for different k values\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"Evaluating K-Means for k = 2 to 10...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    sil_score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette Score={sil_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Elbow Curve and Silhouette Scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow Curve\n",
    "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "axes[0].set_title('Elbow Method for Optimal k', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(list(k_range))\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axvline(x=4, color='r', linestyle='--', alpha=0.7, label='Suggested k=4')\n",
    "axes[0].legend()\n",
    "\n",
    "# Silhouette Score\n",
    "axes[1].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Score for Different k', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(list(k_range))\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "best_k_sil = list(k_range)[np.argmax(silhouette_scores)]\n",
    "axes[1].axvline(x=best_k_sil, color='r', linestyle='--', alpha=0.7, label=f'Best k={best_k_sil}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_elbow_silhouette.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest k based on Silhouette Score: {best_k_sil}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Fit K-Means with Optimal k and Characterize Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2021 data\n",
    "OPTIMAL_K = 4\n",
    "clustering_features = ['Avg_Land_Size', 'Pct_Irrigated', 'Cattle_per_HH', 'Buffalo_per_HH', 'Goat_per_HH', 'Poultry_per_HH']\n",
    "\n",
    "df_2021_full = df_long[df_long['Year'] == 2021].copy()\n",
    "X = df_2021_full[clustering_features].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=OPTIMAL_K, random_state=42, n_init=10)\n",
    "df_2021_full['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "profile_names = {0: 'Commercial Hubs', 1: 'Subsistence Mixed', 2: 'Highland Pastoral', 3: 'Smallholder Diversified'}\n",
    "df_2021_full['Profile'] = df_2021_full['Cluster'].map(profile_names)\n",
    "\n",
    "print('2021 Cluster Distribution:')\n",
    "print(df_2021_full['Cluster'].value_counts().sort_index())\n",
    "print(f'Silhouette Score: {silhouette_score(X_scaled, df_2021_full[\"Cluster\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characterize clusters with detailed profiles\n",
    "cluster_profiles = df_2021_full.groupby('Cluster')[clustering_features].mean()\n",
    "\n",
    "print(\"Cluster Profiles (Mean Values):\")\n",
    "print(\"=\" * 80)\n",
    "display(cluster_profiles.round(2))\n",
    "\n",
    "# Cluster distribution\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(df_2021_full['Cluster'].value_counts().sort_index())\n",
    "\n",
    "# Detailed cluster analysis\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED CLUSTER ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cluster_id in range(OPTIMAL_K):\n",
    "    cluster_data = df_2021_full[df_2021_full['Cluster'] == cluster_id]\n",
    "    print(f\"\\n{'─' * 40}\")\n",
    "    print(f\"CLUSTER {cluster_id}: {profile_names[cluster_id]}\")\n",
    "    print(f\"{'─' * 40}\")\n",
    "    print(f\"Number of Districts: {len(cluster_data)}\")\n",
    "    print(f\"\\nDistricts: {', '.join(cluster_data['Districts'].str.strip().tolist()[:10])}\")\n",
    "    if len(cluster_data) > 10:\n",
    "        print(f\"  ... and {len(cluster_data) - 10} more\")\n",
    "    print(f\"\\nKey Characteristics:\")\n",
    "    for feat in clustering_features:\n",
    "        print(f\"  - {feat}: {cluster_data[feat].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Visualization: Box plots for features across clusters\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(clustering_features):\n",
    "    sns.boxplot(x='Cluster', y=feature, data=df_2021_full, ax=axes[idx], palette='husl')\n",
    "    axes[idx].set_title(feature.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Cluster')\n",
    "    axes[idx].set_ylabel('')\n",
    "\n",
    "plt.suptitle('Feature Distribution Across Clusters (2021)', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_cluster_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Heatmap - Normalized profiles\n",
    "cluster_means = df_2021_full.groupby('Cluster')[clustering_features].mean()\n",
    "cluster_means_normalized = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(cluster_means_normalized.T, annot=cluster_means.T.round(2), \n",
    "            cmap='YlOrRd', fmt='.2f', linewidths=0.5,\n",
    "            xticklabels=[f'C{i}: {profile_names[i][:15]}' for i in range(OPTIMAL_K)],\n",
    "            yticklabels=[f.replace('_', ' ').title() for f in clustering_features])\n",
    "plt.title('Cluster Profiles: Feature Comparison Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster (Profile)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_cluster_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Structural Change Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_structural_change(district_data):\n",
    "    first_decade = district_data[district_data['Year'] <= 1982]\n",
    "    last_decade = district_data[district_data['Year'] >= 2012]\n",
    "    if len(first_decade) == 0 or len(last_decade) == 0:\n",
    "        return 0\n",
    "    changes = []\n",
    "    for col in clustering_features:\n",
    "        early_mean = first_decade[col].mean()\n",
    "        late_mean = last_decade[col].mean()\n",
    "        if early_mean > 0:\n",
    "            changes.append(abs((late_mean - early_mean) / early_mean))\n",
    "    return np.mean(changes) * 100 if changes else 0\n",
    "\n",
    "structural_changes = []\n",
    "for district in df_long['Districts'].unique():\n",
    "    district_data = df_long[df_long['Districts'] == district]\n",
    "    change_index = calculate_structural_change(district_data)\n",
    "    structural_changes.append({'District': district, 'Structural_Change_Index': change_index})\n",
    "\n",
    "df_structural = pd.DataFrame(structural_changes).sort_values('Structural_Change_Index', ascending=False)\n",
    "print('Top 15 Districts by Structural Change:')\n",
    "print(df_structural.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize structural change\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_20 = df_structural.head(20)\n",
    "colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(top_20)))\n",
    "ax.barh(top_20['District'], top_20['Structural_Change_Index'], color=colors)\n",
    "ax.set_xlabel('Structural Change Index (%)')\n",
    "ax.set_title('Top 20 Districts by Structural Change (1972-2021)', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('structural_change_ranking.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecasting (2022-2030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_years = list(range(2022, 2031))\n",
    "\n",
    "forecast_df = pd.DataFrame({'Year': forecast_years})\n",
    "for feature in features:\n",
    "    model = LinearRegression()\n",
    "    model.fit(national_trends['Year'].values.reshape(-1, 1), national_trends[feature].values)\n",
    "    preds = model.predict(np.array(forecast_years).reshape(-1, 1))\n",
    "    forecast_df[feature] = np.clip(preds, 0, None)\n",
    "\n",
    "print('National Forecast (2022-2030):')\n",
    "print(forecast_df.round(2))\n",
    "forecast_df.to_csv('nepal_agriculture_forecast_2030.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "plot_features = ['Poultry_per_HH', 'Avg_Land_Size', 'Pct_Irrigated', 'Cattle_per_HH', 'Goat_per_HH', 'Pig_per_HH']\n",
    "\n",
    "for idx, feature in enumerate(plot_features):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(national_trends['Year'], national_trends[feature], 'b-', linewidth=2, label='Historical')\n",
    "    ax.plot(forecast_df['Year'], forecast_df[feature], 'r--', linewidth=2, label='Forecast')\n",
    "    ax.fill_between(forecast_df['Year'], forecast_df[feature]*0.9, forecast_df[feature]*1.1, alpha=0.2, color='red')\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.set_title(feature.replace('_', ' ').title(), fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvline(x=2021, color='gray', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.suptitle('Agricultural Trends: Historical + Forecast', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('trends_with_forecast.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "X_clf = df_2021_full[clustering_features].copy()\n",
    "y_clf = df_2021_full['Cluster'].copy()\n",
    "\n",
    "print(\"Classification Dataset:\")\n",
    "print(f\"  Features: {X_clf.shape}\")\n",
    "print(f\"  Target distribution:\")\n",
    "print(y_clf.value_counts().sort_index())\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clf, y_clf, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_clf  # Maintain cluster proportions\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set distribution:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nTesting set distribution:\")\n",
    "print(y_test.value_counts().sort_index())\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=4,              # Limit depth for interpretability\n",
    "    min_samples_split=5,      # Minimum samples to split a node\n",
    "    min_samples_leaf=2,       # Minimum samples in a leaf\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Decision Tree Classifier trained successfully!\")\n",
    "print(f\"\\nTree depth: {dt.get_depth()}\")\n",
    "print(f\"Number of leaves: {dt.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Testing Accuracy:  {test_accuracy:.2%}\")\n",
    "\n",
    "# Detailed Classification Report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(\"=\" * 60)\n",
    "target_names = [f\"Cluster {i}: {profile_names[i][:20]}\" for i in range(OPTIMAL_K)]\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[f'C{i}' for i in range(OPTIMAL_K)],\n",
    "            yticklabels=[f'C{i}' for i in range(OPTIMAL_K)])\n",
    "plt.xlabel('Predicted Cluster', fontsize=12)\n",
    "plt.ylabel('Actual Cluster', fontsize=12)\n",
    "plt.title('Confusion Matrix - Decision Tree Classification', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(24, 12))\n",
    "plot_tree(\n",
    "    dt, \n",
    "    feature_names=clustering_features,\n",
    "    class_names=[profile_names[i] for i in range(OPTIMAL_K)],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    proportion=True\n",
    ")\n",
    "plt.title('Decision Tree for Livestock Farming Profile Classification', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_decision_tree.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display decision rules in text format\n",
    "print(\"Decision Tree Rules:\")\n",
    "print(\"=\" * 80)\n",
    "tree_rules = export_text(\n",
    "    dt, \n",
    "    feature_names=clustering_features\n",
    ")\n",
    "print(tree_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from Decision Tree\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': clustering_features,\n",
    "    'importance': dt.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance in Decision Tree Classification', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('temporal_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance.sort_values('importance', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Policy Recommendations and Vulnerability Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate policy recommendations based on cluster characteristics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"POLICY RECOMMENDATIONS BY FARMING PROFILE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = {\n",
    "    0: {\n",
    "        'vulnerability': 'LOW-MEDIUM',\n",
    "        'strengths': [\n",
    "            'Good irrigation infrastructure',\n",
    "            'Diversified livestock portfolio',\n",
    "            'Access to markets'\n",
    "        ],\n",
    "        'challenges': [\n",
    "            'Market price volatility',\n",
    "            'Disease outbreak risks in dense populations'\n",
    "        ],\n",
    "        'recommendations': [\n",
    "            'Establish livestock insurance schemes',\n",
    "            'Develop cold storage and processing facilities',\n",
    "            'Implement disease surveillance systems',\n",
    "            'Promote cooperative marketing'\n",
    "        ]\n",
    "    },\n",
    "    1: {\n",
    "        'vulnerability': 'HIGH',\n",
    "        'strengths': [\n",
    "            'Traditional farming knowledge',\n",
    "            'Low input dependency'\n",
    "        ],\n",
    "        'challenges': [\n",
    "            'Limited irrigation',\n",
    "            'Small land holdings',\n",
    "            'Climate vulnerability',\n",
    "            'Limited market access'\n",
    "        ],\n",
    "        'recommendations': [\n",
    "            'Implement small-scale irrigation projects',\n",
    "            'Provide goat/sheep farming subsidies',\n",
    "            'Establish community pasture management',\n",
    "            'Create mobile veterinary services',\n",
    "            'Develop micro-credit programs'\n",
    "        ]\n",
    "    },\n",
    "    2: {\n",
    "        'vulnerability': 'MEDIUM-HIGH',\n",
    "        'strengths': [\n",
    "            'Large cattle holdings',\n",
    "            'Highland adapted breeds',\n",
    "            'Pastoral traditions'\n",
    "        ],\n",
    "        'challenges': [\n",
    "            'Harsh climate conditions',\n",
    "            'Limited infrastructure',\n",
    "            'Seasonal migration patterns'\n",
    "        ],\n",
    "        'recommendations': [\n",
    "            'Support traditional transhumance practices',\n",
    "            'Improve mountain road connectivity',\n",
    "            'Establish highland breed conservation programs',\n",
    "            'Create seasonal veterinary camps',\n",
    "            'Develop high-altitude fodder cultivation'\n",
    "        ]\n",
    "    },\n",
    "    3: {\n",
    "        'vulnerability': 'MEDIUM',\n",
    "        'strengths': [\n",
    "            'Diversified farming systems',\n",
    "            'Moderate irrigation access',\n",
    "            'Mixed livestock-crop integration'\n",
    "        ],\n",
    "        'challenges': [\n",
    "            'Land fragmentation',\n",
    "            'Labor migration',\n",
    "            'Limited mechanization'\n",
    "        ],\n",
    "        'recommendations': [\n",
    "            'Promote integrated farming systems',\n",
    "            'Support small-scale dairy cooperatives',\n",
    "            'Provide training in improved animal husbandry',\n",
    "            'Develop local feed production',\n",
    "            'Create farmer producer organizations'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "for cluster_id in range(OPTIMAL_K):\n",
    "    rec = recommendations[cluster_id]\n",
    "    print(f\"\\n{'─' * 60}\")\n",
    "    print(f\"CLUSTER {cluster_id}: {profile_names[cluster_id]}\")\n",
    "    print(f\"{'─' * 60}\")\n",
    "    print(f\"\\nVulnerability Level: {rec['vulnerability']}\")\n",
    "    \n",
    "    print(f\"\\nStrengths:\")\n",
    "    for s in rec['strengths']:\n",
    "        print(f\"  ✓ {s}\")\n",
    "    \n",
    "    print(f\"\\nChallenges:\")\n",
    "    for c in rec['challenges']:\n",
    "        print(f\"  ✗ {c}\")\n",
    "    \n",
    "    print(f\"\\nPolicy Recommendations:\")\n",
    "    for i, r in enumerate(rec['recommendations'], 1):\n",
    "        print(f\"  {i}. {r}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Summary\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "                              CONCLUSION\n",
    "================================================================================\n",
    "\n",
    "This study successfully applied machine learning techniques to analyze 50 years\n",
    "of livestock farming data across Nepal's districts (1972-2021).\n",
    "\n",
    "KEY ACHIEVEMENTS:\n",
    "\n",
    "1. DATA GENERATION & EXPLORATION:\n",
    "   - Generated synthetic historical data for 50 years based on 2021 baseline\n",
    "   - Comprehensive EDA performed on all three source datasets\n",
    "   - Feature engineering with 7 key derived indicators\n",
    "\n",
    "2. TEMPORAL TREND ANALYSIS:\n",
    "   - Identified major trends: Poultry commercialization, land fragmentation\n",
    "   - Era-based analysis: Traditional (1972-1985), Early Modern (1986-2000), \n",
    "     Commercial (2001-2021)\n",
    "   - Structural change detection across all districts\n",
    "\n",
    "3. CLUSTERING ANALYSIS:\n",
    "\"\"\")\n",
    "\n",
    "print(f\"   - Identified {OPTIMAL_K} distinct farming profiles using K-Means\")\n",
    "sil = silhouette_score(X_scaled, df_2021_full['Cluster'])\n",
    "print(f\"   - Achieved silhouette score of {sil:.3f}\")\n",
    "print(\"   - Profiles: Commercial Hubs, Subsistence Mixed, Highland Pastoral, Smallholder Diversified\")\n",
    "\n",
    "print(f\"\"\"\n",
    "4. CLASSIFICATION MODEL:\n",
    "   - Decision Tree classifier achieved {test_accuracy:.1%} test accuracy\n",
    "   - Model provides interpretable rules for profile classification\n",
    "   - Key factors identified through feature importance analysis\n",
    "\n",
    "5. FORECASTING:\n",
    "   - Linear trend projection to 2030\n",
    "   - Identified continued poultry growth and land pressure trends\n",
    "\n",
    "6. POLICY IMPLICATIONS:\n",
    "   - Vulnerability assessment for each farming profile\n",
    "   - Targeted recommendations for agricultural interventions\n",
    "   - Evidence-based framework for resource allocation\n",
    "\n",
    "================================================================================\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FILES GENERATED:\")\n",
    "print(\"=\" * 70)\n",
    "output_files = [\n",
    "    ('nepal_agriculture_50_years.csv', '50 years of synthetic district-level data'),\n",
    "    ('nepal_agriculture_forecast_2030.csv', 'National forecast to 2030'),\n",
    "    ('temporal_feature_correlation.png', 'Feature correlation heatmap'),\n",
    "    ('temporal_feature_distributions.png', 'Feature distribution plots'),\n",
    "    ('temporal_pairplot.png', 'Pairwise feature relationships'),\n",
    "    ('temporal_elbow_silhouette.png', 'Cluster selection analysis'),\n",
    "    ('temporal_cluster_boxplots.png', 'Feature distributions by cluster'),\n",
    "    ('temporal_cluster_heatmap.png', 'Cluster profile heatmap'),\n",
    "    ('national_trends_50years.png', '50-year trend analysis'),\n",
    "    ('structural_change_ranking.png', 'District structural change ranking'),\n",
    "    ('trends_with_forecast.png', 'Historical trends with forecast'),\n",
    "    ('temporal_confusion_matrix.png', 'Classification confusion matrix'),\n",
    "    ('temporal_decision_tree.png', 'Decision tree visualization'),\n",
    "    ('temporal_feature_importance.png', 'Feature importance ranking')\n",
    "]\n",
    "\n",
    "for filename, description in output_files:\n",
    "    print(f\"  • {filename}: {description}\")\n",
    "\n",
    "print(f\"\\nTotal data points analyzed: {len(df_long)}\")\n",
    "print(f\"Years covered: 1972-2021 (50 years)\")\n",
    "print(f\"Districts: {df_long['Districts'].nunique()}\")\n",
    "print(f\"Features: {len(features)}\")\n",
    "\n",
    "print(\"\\n✓ 50-Year Temporal Analysis Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
